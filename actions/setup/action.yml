# Copyright 2022 The Sigstore Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name: 'Setup kind cluster, knative, and sigstore scaffolding'
description: 'Install kind, knative, and sigstore scaffolding then test'
branding:
  icon: box
  color: green
inputs:
  version:
    description: 'Version of scaffolding to install (v0.4.0, latest-release.)'
    required: true
    default: 'latest-release'
  knative-version:
    description: 'Version of Knative to install (1.1.0, 1.1.1, etc.)'
    required: true
    default: '1.6.0'
  registry-name:
    description: 'Name of the registry to install (registry.local)'
    required: true
    default: 'registry.local'
  registry-port:
    description: 'Port to run registry on, default 5000'
    required: true
    default: '5000'
  cluster-suffix:
    description: 'Cluster suffix to use. Handy for testing hardcoded assumptions. Default: cluster.local'
    required: true
    default: 'cluster.local'
  k8s-version:
    description: 'kubernetes version to install (v1.21.x, v1.22.x), default: v1.24.x'
    required: true
    default: 'v1.24.x'
runs:
  using: "composite"
  steps:
  - shell: bash
    run: |
      set -ex

      # Configure DockerHub mirror
      tmp=$(mktemp)
      jq '."registry-mirrors" = ["https://mirror.gcr.io"]' /etc/docker/daemon.json > "$tmp"
      sudo mv "$tmp" /etc/docker/daemon.json
      sudo service docker restart

      # Determine which version to install
      # - if version is "latest-release", look up latest release.
      # - otherwise, install the specified version.
      case ${{ inputs.version }} in
      latest-release)
        tag=$(curl -s -u "username:${{ github.token }}" https://api.github.com/repos/sigstore/scaffolding/releases/latest | jq -r '.tag_name')
        ;;
      *)
        tag="${{ inputs.version }}"
      esac

      echo "Installing kind and knative using release"
      curl -Lo ./setup-kind.sh https://github.com/sigstore/scaffolding/releases/download/${tag}/setup-kind.sh
        chmod u+x ./setup-kind.sh
        ./setup-kind.sh \
          --registry-url ${{ inputs.registry-name }}:${{ inputs.registry-port }} \
          --cluster-suffix ${{ inputs.cluster-suffix }} \
          --k8s-version ${{ inputs.k8s-version }} \
          --knative-version ${{ inputs.knative-version }}

      # At release v0.4.0 we added support for TUF, and rejiggered
      # the install process, so check to see if we are running >=4
      MINOR=$(echo $tag | cut -d '.' -f 2)
      INSTALL_TUF="false"
      if [ ${MINOR} -ge 4 ]; then
        INSTALL_TUF="true"
      fi

      echo "Installing sigstore scaffolding @ ${tag}"
      if [ $INSTALL_TUF == "false" ]; then
        echo "This version does not have support for TUF. This is deprecated"
        kubectl apply -f https://github.com/sigstore/scaffolding/releases/download/${tag}/release.yaml

        # Wait for all the scaffolding pieces to be up.
        echo "waiting for all the knative services to be up and running"
        kubectl wait --timeout 10m -A --for=condition=Ready ksvc --all

        # Grab the secret from the ctlog-system namespace and make a copy
        # in our namespace so we can get access to the CT Log public key
        # so we can verify the SCT coming from there.
        kubectl -n ctlog-system get secrets ctlog-public-key -oyaml | sed 's/namespace: .*/namespace: default/' | kubectl apply -f -

        # Also grab the secret from the fulcio-system namespace and make a copy
        # in our namespace so we can get access to the Fulcio public key
        # so we can verify against it.
        kubectl -n fulcio-system get secrets fulcio-secret -oyaml | sed 's/namespace: .*/namespace: default/' | kubectl apply -f -

        echo "Installing and running scaffolding tests to be up and running"
        curl -L https://github.com/sigstore/scaffolding/releases/download/${tag}/testrelease.yaml | kubectl create -f -

        kubectl wait --for=condition=Complete --timeout=180s job/sign-job
        kubectl wait --for=condition=Complete --timeout=180s job/checktree
        kubectl wait --for=condition=Complete --timeout=180s job/verify-job

        kubectl -n ctlog-system get secrets ctlog-public-key -o=jsonpath='{.data.public}' | base64 -d > ./ctlog-public.pem
        echo "SIGSTORE_CT_LOG_PUBLIC_KEY_FILE=./ctlog-public.pem" >> $GITHUB_ENV

        kubectl -n fulcio-system get secrets fulcio-secret -ojsonpath='{.data.cert}' | base64 -d > ./fulcio-root.pem
        echo "SIGSTORE_ROOT_FILE=./fulcio-root.pem" >> $GITHUB_ENV

        echo "SIGSTORE_TRUST_REKOR_API_PUBLIC_KEY=1" >> $GITHUB_ENV
      else
        echo "This version does have support for TUF"
        curl -Lo /tmp/setup-scaffolding-from-release.sh https://github.com/sigstore/scaffolding/releases/download/${tag}/setup-scaffolding-from-release.sh
        chmod u+x /tmp/setup-scaffolding-from-release.sh
        /tmp/setup-scaffolding-from-release.sh
        # We set this here because the other leg doesn't have it.
        TUF_MIRROR=$(kubectl -n tuf-system get ksvc tuf -ojsonpath='{.status.url}')
        echo "TUF_MIRROR=$TUF_MIRROR" >> $GITHUB_ENV

        # Make copy of the tuf root in the default namespace for tests
        kubectl -n tuf-system get secrets tuf-root -oyaml | sed 's/namespace: .*/namespace: default/' | kubectl create -f -

        echo "Installing and running scaffolding tests to be up and running"
        curl -L https://github.com/sigstore/scaffolding/releases/download/${tag}/testrelease.yaml | kubectl create -f -

        kubectl wait --for=condition=Complete --timeout=180s job/sign-job
        kubectl wait --for=condition=Complete --timeout=180s job/verify-job

        # For backward compatibility, add in the old env variables
        # TODO(vaikas): Remove the rest of this block.
        kubectl -n ctlog-system get secrets ctlog-public-key -oyaml | sed 's/namespace: .*/namespace: default/' | kubectl apply -f -

        # Also grab the secret from the fulcio-system namespace and make a copy
        # in our namespace so we can get access to the Fulcio public key
        # so we can verify against it.
        kubectl -n fulcio-system get secrets fulcio-secret -oyaml | sed 's/namespace: .*/namespace: default/' | kubectl apply -f -

        kubectl -n ctlog-system get secrets ctlog-public-key -o=jsonpath='{.data.public}' | base64 -d > ./ctlog-public.pem
        echo "SIGSTORE_CT_LOG_PUBLIC_KEY_FILE=./ctlog-public.pem" >> $GITHUB_ENV

        kubectl -n fulcio-system get secrets fulcio-secret -ojsonpath='{.data.cert}' | base64 -d > ./fulcio-root.pem
        echo "SIGSTORE_ROOT_FILE=./fulcio-root.pem" >> $GITHUB_ENV
        echo "SIGSTORE_TRUST_REKOR_API_PUBLIC_KEY=1" >> $GITHUB_ENV
      fi

      REKOR_URL=$(kubectl -n rekor-system get ksvc rekor -ojsonpath='{.status.url}')
      FULCIO_URL=$(kubectl -n fulcio-system get ksvc fulcio -ojsonpath='{.status.url}')
      CTLOG_URL=$(kubectl -n ctlog-system get ksvc ctlog -ojsonpath='{.status.url}')
      ISSUER_URL=$(kubectl get ksvc gettoken -ojsonpath='{.status.url}')

      # Grab an OIDC token too.
      OIDC_TOKEN=$(curl -s $ISSUER_URL)
      echo "OIDC_TOKEN=$OIDC_TOKEN" >> $GITHUB_ENV

      # And set the env variables for Github action visibility
      echo "REKOR_URL=$REKOR_URL" >> $GITHUB_ENV
      echo "FULCIO_URL=$FULCIO_URL" >> $GITHUB_ENV
      echo "CTLOG_URL=$CTLOG_URL" >> $GITHUB_ENV
      echo "ISSUER_URL=$ISSUER_URL" >> $GITHUB_ENV

